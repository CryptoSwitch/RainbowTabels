#/bin/bash
#This script will break down the large files generated by RainbowTabels.jar into smaller ones and
#rename, sort, and load them into the MySQL database

read -p "File to read? (Use full path, probably /home/gravypod/HashList.txt): " input

split --verbose -a 5 -l 1000000 $input /home/gravypod/test/output/Hashes_pre_entry_   Split into files with 1 million lines each and give them a prefix of "Hashes_pre_entry_" with a 5 character suffix

cd /home/gravypod/test/output

php input.php  #See input.php for comments

declare -a files=`ls Hashes_*`  #Read sorted hash files into an array

for file in $files
do
echo [`date +%H:%M:%S`] Starting $file...

  mysql -u mysql_user -p'mysql_pass' rainbowtables -e "CREATE TABLE IF NOT EXISTS $file (pass VARCHAR(300), hash VARCHAR(40), UNIQUE (hash))";

  mysqlimport -u mysql_user -p"mysql_pass" rainbowtables $file --fields-terminated-by=' ' --lines-terminated-by='\n' --local

cat > $file << EOF  #Empty the file, but leave in tact for next sort/load so as not to load into existing table
EOF

echo $file complete.

done